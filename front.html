<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sign Language Transcription</title>
    <!-- MediaPipe dependencies -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils@0.6/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/hands.js" crossorigin="anonymous"></script>
    <style>
        body { 
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 100%;
            max-width: 800px;
        }
        .video-container {
            position: relative;
            width: 640px;
            height: 480px;
            margin-bottom: 20px;
        }
        #videoElement {
            position: absolute;
            width: 100%;
            height: 100%;
            background-color: #000;
            border: 2px solid black;
        }
        #canvasElement {
            position: absolute;
            width: 100%;
            height: 100%;
            z-index: 10;
        }
        .transcription-container {
            width: 640px;
            margin-top: 20px;
        }
        #transcriptionOutput {
            width: 100%;
            min-height: 100px;
            border: 1px solid #ccc;
            padding: 10px;
            font-size: 18px;
            background-color: #f9f9f9;
        }
        .status {
            margin-top: 10px;
            color: #666;
        }
        .controls {
            margin-top: 20px;
            display: flex;
            gap: 10px;
        }
        button {
            padding: 8px 16px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:hover {
            background-color: #45a049;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Sign Language Transcription</h1>
        
        <div class="video-container">
            <video id="videoElement" autoplay></video>
            <canvas id="canvasElement"></canvas>
        </div>
        
        <div class="status" id="statusElement">Loading hand tracking model...</div>
        
        <div class="transcription-container">
            <h2>Transcription</h2>
            <div id="transcriptionOutput">Sign language transcription will appear here...</div>
        </div>
        
        <div class="controls">
            <button id="clearButton">Clear Transcription</button>
        </div>
    </div>

    <script>
        // We'll initialize these variables after the DOM is loaded
        let videoElement;
        let canvasElement;
        let canvasCtx;
        let statusElement;
        let transcriptionOutput;
        let clearButton;
        
        // MediaPipe objects
        let hands;
        let camera;
        
        // Import MediaPipe drawing utilities
        const mpHands = window.Hands;
        const mpDrawingUtils = window.drawConnectors;
        const mpDrawingStyles = window.drawLandmarks;
        
        // For gesture recognition
        let lastGestureTime = 0;
        let gestureBuffer = [];
        
        // Wait for DOM to load before accessing elements
        document.addEventListener('DOMContentLoaded', function() {
            // Get DOM elements
            videoElement = document.getElementById('videoElement');
            canvasElement = document.getElementById('canvasElement');
            canvasCtx = canvasElement.getContext('2d');
            statusElement = document.getElementById('statusElement');
            transcriptionOutput = document.getElementById('transcriptionOutput');
            clearButton = document.getElementById('clearButton');
            
            // Set canvas dimensions
            canvasElement.width = 640;
            canvasElement.height = 480;
            
            // Initialize MediaPipe Hands
            hands = new Hands({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/${file}`;
                }
            });
            
            // Configure hands
            hands.setOptions({
                maxNumHands: 2,
                modelComplexity: 1,
                minDetectionConfidence: 0.7,
                minTrackingConfidence: 0.7
            });
            
            // Set up result handling
            hands.onResults(onResults);
            
            // Initialize camera
            camera = new Camera(videoElement, {
                onFrame: async () => {
                    try {
                        await hands.send({image: videoElement});
                    } catch (error) {
                        console.error('Error in hand tracking:', error);
                        statusElement.textContent = 'Error in hand tracking: ' + error.message;
                    }
                },
                width: 640,
                height: 480
            });
            
            // Start camera with error handling
            camera.start()
                .then(() => {
                    statusElement.textContent = 'Camera started, tracking hands...';
                    console.log('Camera started successfully');
                })
                .catch(error => {
                    statusElement.textContent = `Error starting camera: ${error.message}`;
                    console.error('Error starting camera:', error);
                });
            
            // Clear button functionality
            clearButton.addEventListener('click', () => {
                gestureBuffer = [];
                transcriptionOutput.textContent = 'Sign language transcription will appear here...';
            });
            
            // Add debugging info
            console.log('DOM loaded, initialization complete');
        });
        
        // Process results from hand tracking
        function onResults(results) {
            // Log results for debugging
            console.log('Got results:', results.multiHandLandmarks ? 
                        `${results.multiHandLandmarks.length} hands detected` : 
                        'No hands detected');
            
            // Clear canvas
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            
            // Draw camera feed on canvas
            canvasCtx.drawImage(
                results.image, 0, 0, canvasElement.width, canvasElement.height
            );
            
            // Update status
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                statusElement.textContent = `Detected ${results.multiHandLandmarks.length} hand(s)`;
                
                // Process each detected hand
                results.multiHandLandmarks.forEach((landmarks, handIndex) => {
                    // Draw hand landmarks with connections
                    window.drawConnectors(
                        canvasCtx, landmarks, mpHands.HAND_CONNECTIONS,
                        {color: '#00FF00', lineWidth: 5}
                    );
                    window.drawLandmarks(
                        canvasCtx, landmarks,
                        {color: '#FF0000', lineWidth: 2, radius: 4}
                    );
                    
                    // Extract and log thumb tip position (similar to Python code)
                    const thumbTip = landmarks[4]; // Thumb tip is index 4
                    console.log(`Hand ${handIndex} Thumb Tip Position: ${thumbTip.x.toFixed(3)}, ${thumbTip.y.toFixed(3)}`);
                    
                    // Basic gesture recognition
                    recognizeGesture(landmarks);
                });
            } else {
                statusElement.textContent = 'No hands detected';
            }
        }
        
        // Simple gesture recognition function
        function recognizeGesture(landmarks) {
            // This is a very basic placeholder for gesture recognition
            // In a real implementation, you would have more sophisticated logic
            
            // Example: Detect if thumb is up (very simplified)
            const thumbTip = landmarks[4];
            const indexFingerTip = landmarks[8];
            
            // Simple check if thumb is higher than index finger
            if (thumbTip.y < indexFingerTip.y) {
                // Throttle gesture detection to avoid rapid changes
                const now = Date.now();
                if (now - lastGestureTime > 1000) { // 1 second cooldown
                    lastGestureTime = now;
                    
                    // Add to gesture buffer
                    gestureBuffer.push("ðŸ‘");
                    
                    // Update transcription
                    if (gestureBuffer.length > 5) {
                        gestureBuffer.shift(); // Keep buffer size limited
                    }
                    transcriptionOutput.textContent = gestureBuffer.join(" ");
                }
            }
        }
    </script>
</body>
</html>
